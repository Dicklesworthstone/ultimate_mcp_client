# Example .env file for MCP Client Multi-Provider
# Copy this file to .env and fill in your details.
# Lines starting with # are comments.

# --- Provider API Keys ---
# Required only for the providers you intend to use.
# Leave blank or omit if not using a specific provider.

ANTHROPIC_API_KEY=""
OPENAI_API_KEY=""
# Used for Gemini models (via OpenAI compatible endpoint OR potentially native SDK later)
GOOGLE_API_KEY=""
GROK_API_KEY=""
DEEPSEEK_API_KEY=""
MISTRAL_API_KEY=""
GROQ_API_KEY=""
CEREBRAS_API_KEY=""
# OPENROUTER_API_KEY="" # If you add OpenRouter support

# --- Provider Base URLs (Optional - for self-hosted/proxies/alternatives) ---
# Override default API endpoints if necessary. Leave blank to use defaults.

OPENAI_BASE_URL=""
# Default: https://generativelanguage.googleapis.com/v1beta (Note: This default might change if using native Gemini SDK)
GEMINI_BASE_URL=""
# Default: https://api.x.ai/v1
GROK_BASE_URL=""
# Default: https://api.deepseek.com
DEEPSEEK_BASE_URL=""
# Default: https://api.mistral.ai/v1
MISTRAL_BASE_URL=""
# Default: https://api.groq.com/openai/v1
GROQ_BASE_URL=""
# Default: https://api.cerebras.ai/v1
CEREBRAS_BASE_URL=""
# OPENROUTER_BASE_URL="https://openrouter.ai/api/v1" # If you add OpenRouter support

# --- Core Client Settings ---

# Default provider to use if model doesn't specify one (e.g., "anthropic", "openai", "gemini").
# Determines which API key is checked/prompted for on startup if missing when in interactive mode.
# Should be one of the values from the Provider enum: openai, anthropic, deepseek, gemini, openrouter, grok, mistral, groq, cerebras
DEFAULT_PROVIDER="anthropic"

# Default model name (should match a model from the default provider or include provider prefix like "openai/gpt-4o")
# See DEFAULT_MODELS in the code for provider-specific defaults if this is not set.
DEFAULT_MODEL="claude-3-5-haiku-20241022"

# Default maximum tokens for the model's response generation (default: 8000)
DEFAULT_MAX_TOKENS="8000"

# Default temperature for generation (0.0-1.0, default: 0.7)
TEMPERATURE="0.7"

# Maximum number of history entries to keep (default: 300)
HISTORY_SIZE="300"

# Enable response streaming (true/false, default: true)
ENABLE_STREAMING="true"

# --- MCP Server Discovery & Connection Settings ---

# Enable automatic filesystem discovery of MCP servers (true/false, default: true)
AUTO_DISCOVER="true"

# Comma-separated list of paths to search for MCP servers
# Default paths are defined in Config.__init__ (usually ~/.mcp-servers, project dirs)
# Example: DISCOVERY_PATHS="/path/to/my/servers,/another/path"
DISCOVERY_PATHS=""

# Enable Zeroconf/mDNS local network discovery (true/false, default: true)
ENABLE_LOCAL_DISCOVERY="true"

# --- Port Scanning ---
# Enable scanning local ports for MCP servers (true/false, default: true)
ENABLE_PORT_SCANNING="true"
# Start port for scanning (default: 8000)
PORT_SCAN_RANGE_START="8000"
# End port for scanning (default: 9000)
PORT_SCAN_RANGE_END="9000"
# Max concurrent port probes (default: 50)
PORT_SCAN_CONCURRENCY="50"
# Timeout per port probe in seconds (default: 4.5)
PORT_SCAN_TIMEOUT="4.5"
# Target IP addresses for port scanning (comma-separated, default: 127.0.0.1)
PORT_SCAN_TARGETS="127.0.0.1"

# --- Caching Settings ---

# Enable caching of tool results (true/false, default: true)
ENABLE_CACHING="true"
# Custom Cache TTLs (Example - Not loaded via decouple, set in config.yaml)
# CACHE_TTL_MAPPING='{"my_tool": 300, "another_tool": 3600}' # Put this in config.yaml

# --- Registry Settings ---

# Enable connecting to remote MCP server registries (true/false, default: true)
ENABLE_REGISTRY="true"
# Comma-separated list of registry URLs to query
REGISTRY_URLS=""

# --- Conversation Optimization Settings ---

# Default model used for summarizing long conversations (should be a capable model)
SUMMARIZATION_MODEL="claude-3-haiku-20240307"
# Enable automatic summarization when context exceeds threshold (true/false, default: false)
USE_AUTO_SUMMARIZATION="false"
# Token threshold to trigger auto-summarization (default: 100000)
AUTO_SUMMARIZE_THRESHOLD="100000"
# Target token count after summarization (default: 1500)
MAX_SUMMARIZED_TOKENS="1500"

# --- Other Settings ---

# Enable OpenTelemetry metrics (true/false, default: true)
ENABLE_METRICS="true"
# Directory to store conversation graph files (default: ./.mcpclient_multi_config/conversations)
CONVERSATION_GRAPHS_DIR=""
# Dashboard refresh rate in seconds (default: 2.0)
DASHBOARD_REFRESH_RATE="2.0"

# --- Debugging ---
# Set to 1 to enable extra verbose logging, including raw MCP session data
# USE_VERBOSE_SESSION_LOGGING="0"
# Set to 1 to enable stdout pollution checks (default: 1, set to 0 to disable)
# MCP_VERIFY_STDOUT="1"
# Set to anything to show full tracebacks on unexpected errors
# MCP_CLIENT_DEBUG="1"